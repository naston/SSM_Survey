# @package _global_
defaults:
  - /trainer: default
  - /loader: torch
  - /dataset: beethoven
  - /task: multiclass_classification
  - /optimizer: adamw
  - /scheduler: plateau
  - /model: samplernn

dataset:
  quantization: linear

model:
  bits: 8
  quantization: linear
  n_rnn: 1
  frame_sizes:
    - 8
    - 2
    - 2

train:
  monitor: val/loss # Needed for plateau scheduler
  mode: min
  state:
    mode: tbptt
    chunk_len: 1024
    overlap_len: 32 # this is model dependent (product of model.frame_sizes here)

task:
  metrics: 
    - bpb
    - accuracy
    - accuracy@3
    - accuracy@5
    - accuracy@10


encoder: null
decoder: null

loader:
  batch_size: 128
  train_resolution: 1
  eval_resolutions:
    - 1

trainer:
  gradient_clip_val: 1.0
  gradient_clip_algorithm: value